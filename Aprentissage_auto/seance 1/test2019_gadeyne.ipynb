{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction à l'apprentissage automatique - Examen\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### Reconnaissance du genre par analyse de la parole\n",
    "\n",
    "<br>\n",
    "\n",
    "La base de donnée [que vous devez télécharger ici](https://members.loria.fr/FSur/enseignement/apprauto/voice2.csv) est construite à partir de 1584 échantillons de voix collectés auprès d'orateurs femmes ou hommes. Chaque échantillon subit une analyse spectrale. Dans la base de données, chaque observation est décrite par les caractéristiques suivantes:\n",
    "\n",
    "   * meanfreq: mean frequency (in kHz)\n",
    "   * sd: standard deviation of frequency\n",
    "   * median: median frequency (in kHz)\n",
    "   * Q25: first quantile (in kHz)\n",
    "   * Q75: third quantile (in kHz)\n",
    "   * IQR: interquantile range (in kHz)\n",
    "   * skew: skewness \n",
    "   * kurt: kurtosis \n",
    "   * label: male (1) or female (0)\n",
    "\n",
    "Vous pouvez ouvrir le fichier `voice2.csv` avec Excel ou un éditeur de texte pour observer les données.\n",
    "\n",
    "_Remarque_: pour réussir cet exercice il n'est pas nécessaire d'avoir compris comment les caractéristiques sont extraites d'un échantillon de voix.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Consignes\n",
    "\n",
    "Seul votre code python doit figurer dans ce carnet Jupyter. Vos réponses doivent être rédigées sur une copie.\n",
    "\n",
    "_Rappel_: le fichier `.ipynb` et le jeu de données `voice2.csv` doivent être dans le même répertoire de travail, et vous devez lancer le serveur `jupyter notebook` dans ce répertoire de manière à ce que vos modifications soient sauvegardées dans le fichier `.ipynb`.\n",
    "\n",
    "Sauvegardez régulièrement votre travail.\n",
    "\n",
    "A la fin du test, faites `Noyau / Redémarrer & effacer les sorties` (barre de commandes en haut du carnet) de manière à générer un fichier `.ipynb` de taille raisonnable, et sauvegardez votre travail. Envoyez votre fichier à l'adresse mail sur@loria.fr.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Travail demandé\n",
    "\n",
    "Le but de l'exercice est de prédire si un échantillon correspond à une voix d'homme ou de femme à partir des 8 caractéristiques fournies. \n",
    "\n",
    "La cellule suivante permet de stocker les vecteurs de caractéristiques et les labels (0 / 1), crée une base d'apprentissage et une base de test de même taille, et normalise les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, neighbors, model_selection, neural_network, svm, linear_model, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# tableau des vecteurs de caractéristiques\n",
    "X = np.genfromtxt('voice2.csv',usecols=(0,1,2,3,4,5,7),skip_header=1,delimiter=';')\n",
    "# vecteur des labels 0/1\n",
    "Y = np.genfromtxt('voice2.csv',usecols=(8),skip_header=1,delimiter=';')\n",
    "\n",
    "print(\"nombre d'observations: %d  -  nombre de caractéristiques par observation: %d\" % (X.shape[0],X.shape[1]))\n",
    "\n",
    "X_tr, X_te, Y_train, Y_test = model_selection.train_test_split(X,Y,test_size=.5)\n",
    "\n",
    "X_train = preprocessing.StandardScaler().fit_transform(X_tr)\n",
    "X_test = preprocessing.StandardScaler().fit(X_tr).transform(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Proposez un classifieur permettant de prédire si un échantillon de voix provient d'un homme ou d'une femme.\n",
    "\n",
    "Vous testerez différents classifieurs dont vous fixerez le ou les hyperparamètre(s) par une méthode que vous préciserez. Vous calculerez un score de classification et la matrice de confusion. Vous expliquerez aussi en quoi consistent ces deux indicateurs.\n",
    "\n",
    "Pourquoi l'entraînement et le test des classifieurs se font-ils sur deux jeux de données différentes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Début rédaction\n",
    "\n",
    "\n",
    "## Questions de cours.\n",
    "\n",
    "Le score de classification indique la proportions de valeurs correctement prédites par le classifieur.\n",
    "\n",
    "La matrice de confusion en i, j indique la quantité d'échantillons appartenant à la classe i ayant été prédits comme appartenants à la classe j.\n",
    "\n",
    "La base de test est différente de la base d'entrainement pour éviter le biais de sur-apprentissage lors de l'évaluation du classifieur (classifieur qui apprend \"par coeur\").\n",
    "\n",
    "## SVM\n",
    "\n",
    "On fait d'abord une première évaluation du classifieur \"naïve\", en choisissant arbitrairement les hyper-paramètres \"gamma\" et  \"C\". Le noyau choisis est \"rbf\", le noyau gaussien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(C=0.1, gamma='scale', kernel = \"rbf\")    \n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "print(\"score SVM %.2f\" % clf.score(X_test, Y_test) )\n",
    "print(\"nombre de vecteurs supports : \", clf.n_support_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a alors un score de prédiction de 0.9 sur la base de test.\n",
    "On va ensuite chercher à afficer ces paramètres, a l'aide de la fonction \"gridsearch\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_range=10**(np.arange(-3.,4.5,.5))\n",
    "C_range=10**(np.arange(-3.,3.5,.5)) \n",
    "parameters = { 'gamma': gamma_range, 'C':C_range }\n",
    "SVM = svm.SVC(kernel='rbf')\n",
    "gridsearch=model_selection.GridSearchCV(SVM, parameters)\n",
    "gridsearch.fit(X_train,Y_train)\n",
    "print(\"Meilleur estimateur trouvé:\")\n",
    "print(gridsearch.best_estimator_)\n",
    "print(\"Meilleurs paramètres:\")\n",
    "print(gridsearch.best_params_)\n",
    "\n",
    "scores = gridsearch.cv_results_['mean_test_score'].reshape(len(C_range),len(gamma_range))\n",
    "plt.figure(figsize=[10,10])\n",
    "plt.imshow(scores)\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('C')\n",
    "plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "plt.yticks(np.arange(len(C_range)), C_range)\n",
    "plt.colorbar()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le meilleur couple de valeurs trouvé est : C = 100, gamma = 0.032. Regardons maintenant le meilleur noyau pour ce couple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "for kernel in kernels : \n",
    "    clf = svm.SVC(C=100, gamma=0.032, kernel = kernel)    \n",
    "    clf.fit(X_train, Y_train)\n",
    "\n",
    "    print(\"score SVM : %.2f\" % clf.score(X_test, Y_test), \"pour le noyau \", kernel )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semble donc que le noyau 'rbf' soit le meilleur. Pour en être sûr, je réeffectue un gridsearch avec le moins bon noyau (sigmoid) pour voir si les valeurs varient fortement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_range=10**(np.arange(-3.,4.5,.5))\n",
    "C_range=10**(np.arange(-3.,3.5,.5)) \n",
    "parameters = { 'gamma': gamma_range, 'C':C_range }\n",
    "SVM = svm.SVC(kernel='sigmoid')\n",
    "gridsearch=model_selection.GridSearchCV(SVM, parameters)\n",
    "gridsearch.fit(X_train,Y_train)\n",
    "print(\"Meilleur estimateur trouvé:\")\n",
    "print(gridsearch.best_estimator_)\n",
    "print(\"Meilleurs paramètres:\")\n",
    "print(gridsearch.best_params_)\n",
    "\n",
    "scores = gridsearch.cv_results_['mean_test_score'].reshape(len(C_range),len(gamma_range))\n",
    "plt.figure(figsize=[10,10])\n",
    "plt.imshow(scores)\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('C')\n",
    "plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "plt.yticks(np.arange(len(C_range)), C_range)\n",
    "plt.colorbar()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les valeurs sont modifiées, mais on reste sur un score inférieeur à 'rbf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce qui est de la matrice de confusion :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "clf = svm.SVC(C=100, gamma=0.032, kernel = 'rbf')    \n",
    "clf.fit(X_train, Y_train)\n",
    "Y_test_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"score MLP %.4f\" % clf.score(X_test, Y_test) )\n",
    "print(metrics.confusion_matrix(Y_test,Y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP à une couche.\n",
    "\n",
    "on test ici la classification par un perceptron à une couche cachée (20 neurones). On cherchera les bonnes valeurs pour les hyperparamètres alpha et max_iter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec relu en fonction d'activation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "alpha_range=10**(np.arange(-4.8,-3.2,.1))\n",
    "max_iter_range=10**(np.arange(2,2.7,.1)) \n",
    "# alpha_range=np.arange(0.00005,0.00015,0.0001)\n",
    "# max_iter_range=np.arange(100,500,50)\n",
    "parameters = { 'alpha': alpha_range, 'max_iter':max_iter_range }\n",
    "SVM = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(20), random_state=1, activation = 'relu')\n",
    "gridsearch=model_selection.GridSearchCV(SVM, parameters)\n",
    "gridsearch.fit(X_train,Y_train)\n",
    "print(\"Meilleur estimateur trouvé:\")\n",
    "print(gridsearch.best_estimator_)\n",
    "print(\"Meilleurs paramètres:\")\n",
    "print(gridsearch.best_params_)\n",
    "\n",
    "scores = gridsearch.cv_results_['mean_test_score'].reshape(len(max_iter_range),len(alpha_range))\n",
    "# plt.figure(figsize=[10,10])\n",
    "plt.imshow(scores)\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('max_iter')\n",
    "plt.xticks(np.arange(len(alpha_range)), alpha_range, rotation=45)\n",
    "plt.yticks(np.arange(len(max_iter_range)), max_iter_range)\n",
    "plt.colorbar()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "avec la sigmoide :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_range=10**(np.arange(-5.2,-3.2,.1))\n",
    "max_iter_range=10**(np.arange(2,2.7,.1)) \n",
    "# alpha_range=np.arange(0.00005,0.00015,0.0001)\n",
    "# max_iter_range=np.arange(100,500,50)\n",
    "parameters = { 'alpha': alpha_range, 'max_iter':max_iter_range }\n",
    "SVM = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(20), random_state=1, activation = 'logistic')\n",
    "gridsearch=model_selection.GridSearchCV(SVM, parameters)\n",
    "gridsearch.fit(X_train,Y_train)\n",
    "print(\"Meilleur estimateur trouvé:\")\n",
    "print(gridsearch.best_estimator_)\n",
    "print(\"Meilleurs paramètres:\")\n",
    "print(gridsearch.best_params_)\n",
    "\n",
    "scores = gridsearch.cv_results_['mean_test_score'].reshape(len(max_iter_range),len(alpha_range))\n",
    "# plt.figure(figsize=[10,10])\n",
    "plt.imshow(scores)\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('max_iter')\n",
    "plt.xticks(np.arange(len(alpha_range)), alpha_range, rotation=45)\n",
    "plt.yticks(np.arange(len(max_iter_range)), max_iter_range)\n",
    "plt.colorbar()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les scores obtenus sont similaires, on garde la sigmoide, avec alpha =  0.0004 et max_iter = 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=4e-4, max_iter = 250, hidden_layer_sizes=(20), random_state=1, activation = 'logistic')\n",
    "  \n",
    "clf.fit(X_train, Y_train)\n",
    "Y_test_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"score MLP %.4f\" % clf.score(X_test, Y_test) )\n",
    "print(metrics.confusion_matrix(Y_test,Y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce classifieur semble sensiblement moins performant que la machine a vecteur support, on peut voir qu'il y a 10 échantillons mal classés supplémentaires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plus proches voisins.\n",
    "\n",
    "on teste enfin la méthode des plus proches voisins. On cherchera a determiner le bon nombre de voiosinns à considérer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for i in range(1,20):\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=i)\n",
    "    results.append([i, knn.fit(X_train, Y_train).score(X_test, Y_test)])\n",
    "\n",
    "plt.plot([results[i][0] for i in range(len(results))], [results[i][1] for i in range(len(results))], 'ro')\n",
    "plt.axis([0, 20, 0.90, 0.95])\n",
    "plt.show()\n",
    "    \n",
    "for k in results:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le meilleur résultat est obtenu avec 3 plus proches voisins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_test_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"score MLP %.4f\" % clf.score(X_test, Y_test) )\n",
    "print(metrics.confusion_matrix(Y_test,Y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient des résultats à peu près équivalents aux deux autres classifieurs : plus de 0.93\n",
    "\n",
    "Cependant, on peut voir que la matrice de confusion est différente : les erreurs de prédiction des échantillons de la classe 1 sont plus faibles que ceux de la classe 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion.\n",
    "\n",
    "Pour ce problème, je choisirai une machine à vecteurs supports, avec pour paramètres :\n",
    "\n",
    "- kernel = 'rbf'\n",
    "- C = 100 \n",
    "- gamma = 0.032\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
